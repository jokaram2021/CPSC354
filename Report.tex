\documentclass{article}

\usepackage{tikz} 
\usetikzlibrary{automata, positioning, arrows} 

\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{fullpage}
\usepackage{color}
\usepackage{parskip}
\usepackage{hyperref}
  \hypersetup{
    colorlinks = true,
    urlcolor = blue,
    linkcolor= blue,
    citecolor= blue,
    filecolor= blue,
    }
    
\usepackage{listings}
\usepackage[utf8]{inputenc}                                                    
\usepackage[T1]{fontenc}                                                       

\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

\lstset{frame=tb,
  language=haskell,
  aboveskip=3mm,
  belowskip=3mm,
  showstringspaces=false,
  columns=flexible,
  basicstyle={\small\ttfamily},
  numbers=none,
  numberstyle=\tiny\color{gray},
  keywordstyle=\color{blue},
  commentstyle=\color{dkgreen},
  stringstyle=\color{mauve},
  breaklines=true,
  breakatwhitespace=true,
  tabsize=3
}

\newtheoremstyle{theorem}
  {\topsep}{\topsep}{\itshape\/}{0pt}{\bfseries}{.}{5pt plus 1pt minus 1pt}{}
\theoremstyle{theorem} 
   \newtheorem{theorem}{Theorem}[section]
   \newtheorem{corollary}[theorem]{Corollary}
   \newtheorem{lemma}[theorem]{Lemma}
   \newtheorem{proposition}[theorem]{Proposition}
\theoremstyle{definition}
   \newtheorem{definition}[theorem]{Definition}
   \newtheorem{example}[theorem]{Example}
\theoremstyle{remark}    
  \newtheorem{remark}[theorem]{Remark}

\setcounter{tocdepth}{3}
\setcounter{secnumdepth}{3}

\title{CPSC-354 Report}
\author{Jonathan Karam \\ Chapman University}

\date{\today} 

\begin{document}

\maketitle

\begin{abstract}
This report is a collection of notes, discussions, and homework solutions for CPSC 354. 
Homework 1 discusses the MIU puzzle and proves why \texttt{MI} cannot become \texttt{MU}. 
Homework 2 introduces abstract rewriting systems (ARS), includes TikZ diagrams, and classifies systems by termination, confluence, and unique normal forms. 
Homework 3 studies a rewriting system over $\{a,b\}$ and explores its equivalence classes and termination.
Homework 4 proves termination of two classic algorithms using measure functions.
Homework 5 evaluates a small $\lambda$-calculus ``workout'' using $\alpha$- and $\beta$-rules, with notes connecting these ideas to modern languages.
Homework 6 develops fixpoints and recursion: we compute \texttt{fact 3} step-by-step with the rules for \texttt{fix}, \texttt{let}, and \texttt{let rec}, and give a Y-combinator encoding of factorial.
Week 7 covers grammars, parse trees, and ASTs with full derivation trees.
Week 8 connects the Natural Number Game (Tutorial World) to natural-language proofs and Lean tactics, with scripts for Levels 5--8 and a short class-notes discussion.
\end{abstract}

\tableofcontents

\section{Introduction}
This report documents my learning week by week. 
Each section includes my notes and discussions of the lecture topics, followed by my homework solutions.
The purpose is to show understanding, practice writing in \LaTeX{}, and explain the material in my own words.

\section{Week 1: The MIU Puzzle}

\subsection{Notes and Discussion}
The first week introduced the MIU puzzle, created by Douglas Hofstadter. 
It is a formal system that begins with the word \texttt{MI} and has four rules. 
The puzzle asks whether it is possible to reach \texttt{MU}. 
This is important because it shows how formal systems can be analyzed with invariants, a key concept in logic and computer science.

\subsection{Homework}
\textbf{Rules:}
\begin{enumerate}
  \item If a string ends with \texttt{I}, add a \texttt{U}.
  \item If a string starts with \texttt{M}, double the part after \texttt{M}.
  \item Replace \texttt{III} with \texttt{U}.
  \item Remove \texttt{UU}.
\end{enumerate}

\textbf{Why \texttt{MI} cannot become \texttt{MU}:}  
Let $\#I(w)$ be the number of \texttt{I}'s in $w$. Initially $\#I(\texttt{MI})=1$. 
Each rule preserves $\#I(w) \pmod{3}$:
\begin{itemize}
  \item Rule 1: no effect.
  \item Rule 2: doubles the count, $1 \mapsto 2$, never $0 \pmod 3$.
  \item Rule 3: subtracts 3, same remainder.
  \item Rule 4: no effect.
\end{itemize}
Thus $\#I(w) \pmod{3}$ is invariant. Since \texttt{MU} has $\#I=0$, it cannot be reached.

\textbf{Deeper explanation:}  
The invariant argument proves that all reachable words have I-count $\equiv 1$ or $2 \pmod{3}$, never 0.  
The first letter $M$ never disappears, so all reachable words start with $M$.  
Another way: define a homomorphism $h(M)=0, h(U)=0, h(I)=1 \pmod 3$. 
Every rule preserves $h$, so $h(\texttt{MI})=1$ and $h(\texttt{MU})=0$. Contradiction.  

\section{Week 2: Abstract Rewriting Systems}

\subsection{Notes and Discussion}
This week focused on abstract rewriting systems. 
An ARS consists of a set $A$ and a relation $R$. 
We ask whether rewriting always stops (termination), whether different rewrite paths can rejoin (confluence), and whether elements end up in unique normal forms.

\subsection{Homework}
\emph{Same problem statement as before:} draw each ARS and decide termination, confluence, and whether the system has \emph{unique normal forms for all elements} (UN-for-all).

\subsubsection*{Examples (drawings unchanged)}
\begin{tikzpicture}
  % Example 1
\end{tikzpicture}

\textbf{1: $A=\{\}, R=\{\}$} (empty system)

\begin{tikzpicture}
  \node[draw,circle] (a) at (0,0) {a};
\end{tikzpicture}

\textbf{2: $A=\{a\}, R=\{\}$}

\begin{tikzpicture}
  \node[draw,circle] (a) at (0,0) {a};
  \draw[->] (a) to[loop above] (a);
\end{tikzpicture}

\textbf{3: $A=\{a\}, R=\{(a,a)\}$}

\begin{tikzpicture}
  \node[draw,circle] (a) at (0,0) {a};
  \node[draw,circle] (b) at (2,0) {b};
  \node[draw,circle] (c) at (2,-1) {c};
  \draw[->] (a) -- (b);
  \draw[->] (a) -- (c);
\end{tikzpicture}

\textbf{4: $A=\{a,b,c\}, R=\{(a,b),(a,c)\}$}

\begin{tikzpicture}
  \node[draw,circle] (a) at (0,0) {a};
  \node[draw,circle] (b) at (2,0) {b};
  \draw[->] (a) to[loop above] (a);
  \draw[->] (a) -- (b);
\end{tikzpicture}

\textbf{5: $A=\{a,b\}, R=\{(a,a),(a,b)\}$}

\begin{tikzpicture}
  \node[draw,circle] (a) at (0,0) {a};
  \node[draw,circle] (b) at (2,0) {b};
  \node[draw,circle] (c) at (2,-1) {c};
  \draw[->] (a) -- (b);
  \draw[->] (a) -- (c);
  \draw[->] (b) to[loop above] (b);
\end{tikzpicture}

\textbf{6: $A=\{a,b,c\}, R=\{(a,b),(b,b),(a,c)\}$}

\begin{tikzpicture}
  \node[draw,circle] (a) at (0,0) {a};
  \node[draw,circle] (b) at (2,0) {b};
  \node[draw,circle] (c) at (2,-1) {c};
  \draw[->] (a) -- (b);
  \draw[->] (a) -- (c);
  \draw[->] (b) to[loop above] (b);
  \draw[->] (c) to[loop right] (c);
\end{tikzpicture}

\textbf{7: $A=\{a,b,c\}, R=\{(a,b),(b,b),(a,c),(c,c)\}$}

\subsubsection*{Classification (solutions rewritten)}
We now use \textbf{UN-for-all}: every element must have a (unique) normal form.

\[
\begin{array}{c|c|c|c|l}
\text{ARS} & \text{Terminating} & \text{Confluent} & \text{UN-for-all} & \text{Why} \\\hline
1 & \text{Yes} & \text{Yes} & \text{Yes} & \text{Nothing rewrites (vacuous).} \\
2 & \text{Yes} & \text{Yes} & \text{Yes} & a \text{ is already normal and unique.} \\
3 & \text{No} & \text{Yes} & \text{No}  & a \to a \text{ forever; } a \text{ has no NF.} \\
4 & \text{Yes} & \text{No}  & \text{No}  & a\to b,\,a\to c \text{ (two distinct NFs).} \\
5 & \text{No} & \text{Yes} & \text{Yes} & a\to b,\; b \text{ normal; both end at } b. \\
6 & \text{No} & \text{No}  & \text{No}  & b \text{ loops; } a\to c \text{ NF, not joinable with } b. \\
7 & \text{No} & \text{No}  & \text{No}  & b,c \text{ loop; no element has an NF.} \\
\end{array}
\]

\paragraph{Remarks.}
\begin{itemize}
  \item Non-termination alone does not rule out UN-for-all (see 5), but any element without an NF breaks it (3,6,7).
  \item In terminating ARSs, confluence $\Rightarrow$ UN-for-all (every element reaches a unique NF).
  \item Item 4 is the canonical ``diamond failure'': two different normal forms reachable from the same source.
\end{itemize}

\section{Week 3: Strings over \{a,b\}}

\subsection{Notes and Discussion}
We studied rewriting rules over alphabet $\{a,b\}$. 
This shows how simple systems can classify strings into equivalence classes. 
We also saw how orienting rules one way can make a system terminating without changing equivalence.

\subsection{Homework 3}
\textbf{Exercise 5 rules:}
\[
ab \to ba,\quad ba \to ab,\quad aa \to \varepsilon,\quad b \to \varepsilon
\]

Examples: \texttt{abba} $\to$ \texttt{aa} $\to$ $\varepsilon$.  
\texttt{bababa} $\to$ \texttt{aaa} $\to$ \texttt{a}.  

Not terminating because swaps loop.  
Equivalence classes: even number of $a$’s $\to \varepsilon$, odd $\to a$.  
Normal forms: $\varepsilon, a$.  
Fix: orient $ba \to ab$ only.  

\textbf{Exercise 5b rules:}
\[
ab \leftrightarrow ba,\quad aa \to a,\quad b \to \varepsilon
\]

Examples: \texttt{abba} $\to$ \texttt{a}. \texttt{bababa} $\to$ \texttt{a}.  

Equivalence: all $b$ vanish, runs of $a$ collapse to one $a$.  
Classes: $\{\varepsilon,a\}$.  
Fix: orient swaps, keep $aa \to a$ and $b \to \varepsilon$.  

\section{Week 4: Measure Functions and Termination}

\subsection{Notes and Discussion}
This week we looked at \emph{measure functions} to prove that algorithms terminate.
A measure maps the state of a computation to a value in a well-founded set (usually the natural numbers) and must
\emph{strictly decrease} with every loop iteration or recursive call. Because there are no infinite descending chains in a well-founded set, the computation must eventually stop.

\textbf{Scope note:} Here we define a measure and show it strictly decreases.

\paragraph{Class notes invariant proof that Euclid returns $\gcd$.}
\begin{itemize}
  \item \textbf{Key fact.} $\gcd(a,b)=\gcd\!\big(b,\,a-qb\big)$ for any integer $q$.
  \item \textbf{Update.} Writing $a=qb+r$ with $r=a\bmod b$, the step $(a,b)\mapsto(b,r)$ keeps the gcd unchanged.
  \item \textbf{Invariant.} Before each loop test: $\gcd(a,b)=\gcd(a_0,b_0)$.
  \item \textbf{End.} When $b=0$, $\gcd(a_0,b_0)=\gcd(a,0)=|a|$, the returned value.
\end{itemize}

\subsection{Homework 4}

\subsubsection*{HW 4.1}
\textbf{Problem.} Considering
\begin{lstlisting}[language=Python]
while b != 0:
    temp = b
    b = a % b
    a = temp
return a
\end{lstlisting}
Under which conditions does this algorithm always terminate? Find a measure function and prove termination.

\medskip
\textbf{Answer.}  
This is the classical Euclidean algorithm for $\gcd(a,b)$. It always terminates provided that
\[
a,b \in \mathbb{Z}\quad\text{and}\quad b \ge 0,
\]
and we interpret \texttt{\%} as the mathematical remainder with $0 \le a \bmod b < b$ for $b>0$. If the inputs are negative, replace them once by $|a|,|b|$; this preserves $\gcd$ and satisfies the condition.

\paragraph{Measure function.}
Let the program state be the pair $(a,b)$ with $b \ge 0$. Define
\[
\mu(a,b) \;=\; b \in \mathbb{N}.
\]

\paragraph{Strict decrease.}
In an iteration with $b>0$ we set $b' = a \bmod b$. By definition of remainder,
\[
0 \le b' < b.
\]
Therefore $\mu(a',b') = b' < b = \mu(a,b)$. Hence $\mu$ strictly decreases on every loop step.

\paragraph{Well-foundedness and termination.}
$\mu$ maps states to the natural numbers with the usual $<$, which is well founded.  
Because $\mu$ strictly decreases whenever the loop body executes, the loop can execute only finitely many times; eventually $b=0$ and the algorithm returns. \qed

\begin{remark}
The algorithm not only terminates; it returns $\gcd(a,b)$. This follows from the class note invariant above and $\gcd(a,0)=|a|$.
\end{remark}

\subsubsection*{HW 4.2}
\textbf{Problem.} Consider the fragment of merge sort:
\begin{lstlisting}[language=Python]
def merge_sort(arr, left, right):
    if left >= right:
        return
    mid = (left + right) // 2
    merge_sort(arr, left, mid)
    merge_sort(arr, mid + 1, right)
    merge(arr, left, mid, right)
\end{lstlisting}
Prove that
\[
\varphi(left,right) \;=\; right - left + 1
\]
is a measure function for \texttt{merge\_sort}.

\medskip
\textbf{Answer.}
We show that every recursive call is made with a \emph{strictly smaller} measure and that the measure is bounded below by $0$.

\paragraph{Well-founded codomain.}
$\varphi(left,right)$ is a nonnegative integer whenever $left\le right$, so the codomain is $\mathbb{N}$ with the usual $<$ (well-founded).

\paragraph{Base case.}
If $left \ge right$, the function returns immediately. In this case $\varphi \le 1$, and there are no recursive calls.

\paragraph{Decrease for recursive calls.}
Assume $left < right$ and let $n = \varphi(left,right) = right-left+1 \ge 2$. With
\[
mid = \left\lfloor \frac{left+right}{2} \right\rfloor,
\]
the first recursive call is on $[left,\,mid]$ and the second on $[mid+1,\,right]$. Their measures are
\[
\varphi(left,mid) = mid - left + 1, \qquad
\varphi(mid+1,right) = right - mid.
\]
Because $left \le mid < right$, we have
\[
1 \le \varphi(left,mid) \le \left\lceil \frac{n}{2}\right\rceil < n,\qquad
1 \le \varphi(mid+1,right) \le \left\lfloor \frac{n}{2}\right\rfloor < n.
\]
Thus each recursive call receives strictly smaller measure than $n$.

\paragraph{Conclusion.}
Every chain of recursive calls strictly decreases $\varphi$ and cannot be infinite in $\mathbb{N}$. Therefore \texttt{merge\_sort} terminates. \qed

\section{Week 5: Lambda Calculus Foundations}

\subsection{Notes and Discussion}
\begin{itemize}
  \item \textbf{Self-application and computation.} Terms like $(\lambda x.\,xx)(\lambda x.\,xx)$ show that functions can take \emph{code as data}. This enables iteration/recursion encodings (fixed points) and explains why untyped $\lambda$ can express non-termination.
  \item \textbf{Where $\lambda$ shines.} Useful for building \emph{minimal cores}: interpreters, proof assistants, type checkers, compiler IRs, and reasoning about higher-order functions. It models substitution, scope, closures, and evaluation precisely.
  \item \textbf{Composition and numerals.} Church numerals encode iteration: $\mathbf{n}\,f\,x = f^{n}x$. Function composition $(f \circ g)$ corresponds to multiplying numerals: $(\mathbf{m}\circ\mathbf{n})\,f\,x = f^{mn}x$. Plain application behaves like \emph{exponentiation in reverse order}: $\mathbf{m}\,\mathbf{n} = \mathbf{n}^{\,\mathbf{m}}$ (apply $\mathbf{m}$ times), so $\mathbf{2}\,\mathbf{3}=\mathbf{9}$ and $\mathbf{3}\,\mathbf{2}=\mathbf{8}$.
  \item \textbf{Confluence (Church–Rosser).} If a term reduces to two results, there exists a common reduct. Meaning: evaluation order doesn’t affect the final normal form (when it exists). Languages borrow this idea to justify equational reasoning and optimizations.
  \item \textbf{From $\lambda$ to languages.} Add types (safety), effects (state, I/O), data types, and evaluation strategy to get modern languages. Typed $\lambda$-calculi (System~F, Hindley–Milner) underlie ML/Haskell; effect systems/monads model side effects.
  \item \textbf{Haskell links.} Purity, first-class functions, laziness (normal-order–like), algebraic data types, and type inference all line up with typed $\lambda$-calculus. Monads/Applicatives are structured ways to compose computations.
  \item \textbf{Names and $\alpha$-conversion.} Variables need not be single letters; names are irrelevant up to $\alpha$-equivalence (consistent renaming). Modern languages reflect this via lexical scope, hygienic macros, and compiler renaming to avoid capture.
  \item \textbf{The role of $\alpha$ in practice.} Compilers implement renaming and fresh-name generation to maintain scope hygiene (e.g., SSA form, macro expansion).
  \item \textbf{Termination and type systems.} Untyped $\lambda$ allows non-termination (Y-combinator). Total languages (Coq/Agda) \emph{forbid} general recursion by checking termination via structural/lexicographic and multivariate measures; complex patterns (exponential, multi-dimension decrease) are handled with well-founded orders and sized types.
  \item \textbf{Original intent.} Church invented $\lambda$ for the foundations of mathematics and to study effective computability—leading to Church–Turing thesis.
  \item \textbf{Recursion vs loops.} Prefer recursion for recursive structure or immutability; prefer loops for in-place iteration or where tail recursion isn’t optimized.
\end{itemize}

\subsection{Homework 5: Lambda Calculus Workout}

\subsubsection*{Problem}
Evaluate (practice $\alpha$ and $\beta$ rules; match parentheses):
\[
\Big(\lambda f.\,\lambda x.\,f(f\,x)\Big)\;
\Big(\lambda f.\,\lambda x.\,f(f(f\,x))\Big).
\]

\subsubsection*{Solution}
Let
\[
\mathbf{two} \equiv \lambda f.\lambda x.\,f(fx),\qquad
\mathbf{three} \equiv \lambda f.\lambda x.\,f(f(fx)).
\]
Then
\[
\mathbf{two}\;\mathbf{three}
\;\xrightarrow{\beta}\;
\lambda x.\,\mathbf{three}\,(\mathbf{three}\,x).
\]
Compute:
\[
\mathbf{three}\,x \xrightarrow{\beta} \lambda y.\,x(x(x\,y)),
\qquad
\mathbf{three}\,(\lambda y.\,x(x(x\,y))) \xrightarrow{\beta} \lambda z.\,x^{9}z.
\]
Therefore
\[
\boxed{\lambda x.\lambda z.\,x^{9}z}
\]
which is the Church numeral $\mathbf{nine}$.
(And $\mathbf{3}\,\mathbf{2}=\mathbf{8}$ because $\mathbf{m}\,\mathbf{n}=\mathbf{n}^{\,\mathbf{m}}$.)

% ============================
\section{Week 6: Fixpoints and Recursion}
% ============================

\subsection{Class Notes \& Discussion}
This section responds concisely to discussion questions from class.

\begin{enumerate}
  \item \textbf{Reducing inside larger expressions and step rules for \texttt{fix}, \texttt{let}, \texttt{if}.}
  We use \emph{evaluation contexts}: reduce inside the syntactic position allowed by the strategy (e.g., call-by-value reduces the scrutinee of \texttt{if}, the bound expression of \texttt{let}, and the argument to \texttt{fix} until it is a $\lambda$). Rules:
  \[
  \mathrm{fix}\ F \;\to\; F(\mathrm{fix}\ F),\qquad
  \mathrm{let}\ x=e_1\ \mathrm{in}\ e_2 \;\to\; (\lambda x.\,e_2)\,e_1,\qquad
  \mathrm{if}\ \text{true}\ \text{then}\ e_1\ \text{else}\ e_2 \to e_1.
  \]
  Contexts justify each inner step when \texttt{fix}, \texttt{let}, or \texttt{if} appears inside a bigger term.

  \item \textbf{Fixpoint combinator and recursion.}
  A combinator $Y$ with $YF = F(YF)$ provides a value $YF$ that is a fixed point of $F$. If $F$ encodes one step of a recursive definition, $YF$ is its recursive solution. Languages often bake this in as a primitive \texttt{fix}.

  \item \textbf{Factorial with $Y$ instead of \texttt{fix}.}
  \[
  \mathrm{fact} \;\equiv\; Y\,(\lambda f.\,\lambda n.\ \mathrm{if}\ n=0\ \mathrm{then}\ 1\ \mathrm{else}\ n \cdot f(n-1)).
  \]

  \item \textbf{Typed vs untyped.} In typed, strongly normalizing calculi, general $Y$ breaks termination; practical languages use explicit recursion with typing restrictions, or domain-theoretic semantics for effects.
\end{enumerate}

\subsection{Homework 6}

We use these computation rules:
\[
\mathrm{fix}\ F \to F(\mathrm{fix}\ F),\quad
\mathrm{let}\ x=e_1\ \mathrm{in}\ e_2 \to (\lambda x.\,e_2)\,e_1,\quad
\mathrm{let\ rec}\ f=e_1\ \mathrm{in}\ e_2 \to \mathrm{let}\ f=(\mathrm{fix}\ (\lambda f.\,e_1))\ \mathrm{in}\ e_2.
\]

\subsubsection*{Problem A: Compute \texttt{fact 3}}
Start with
\[
\mathrm{let\ rec}\ \mathrm{fact} = \lambda n.\ \mathrm{if}\ n=0\ \mathrm{then}\ 1\ \mathrm{else}\ n * \mathrm{fact}(n-1)\ \mathrm{in}\ \mathrm{fact}\ 3.
\]

\noindent\textbf{Derivation}
\[
\begin{aligned}
&\mathrm{let\ rec}\ \mathrm{fact}=\lambda n.\ \mathrm{if}\ n=0\ \mathrm{then}\ 1\ \mathrm{else}\ n * \mathrm{fact}(n-1)\ \mathrm{in}\ \mathrm{fact}\ 3\\
\to\ &\text{\textbf{(def of let rec)}}\\
&\mathrm{let}\ \mathrm{fact}=\mathrm{fix}\ (\lambda f.\ \lambda n.\ \mathrm{if}\ n=0\ \mathrm{then}\ 1\ \mathrm{else}\ n * f(n-1))\ \mathrm{in}\ \mathrm{fact}\ 3\\
\to\ &\text{\textbf{(def of let)}}\\
&(\lambda \mathrm{fact}.\ \mathrm{fact}\ 3)\ \big(\mathrm{fix}\ F\big)
\quad\text{where }F \equiv \lambda f.\ \lambda n.\ \mathrm{if}\ n=0\ \mathrm{then}\ 1\ \mathrm{else}\ n * f(n-1)\\
\to\ &\text{\textbf{($\beta$; substitute $\mathrm{fix}\ F$ for fact)}}\\
&(\mathrm{fix}\ F)\ 3\\
\to\ &\text{\textbf{(def of fix)}}\\
&\big(F(\mathrm{fix}\ F)\big)\ 3\\
\to\ &\text{\textbf{($\beta$)}}\\
&(\lambda n.\ \mathrm{if}\ n=0\ \mathrm{then}\ 1\ \mathrm{else}\ n * (\mathrm{fix}\ F)(n-1))\ 3\\
\to\ &\text{\textbf{($\beta$; substitute $3$ for $n$)}}\\
&\mathrm{if}\ 3=0\ \mathrm{then}\ 1\ \mathrm{else}\ 3 * (\mathrm{fix}\ F)(2)\\
\to\ &\text{\textbf{(def of if)}}\\
&3 * (\mathrm{fix}\ F)(2)\\
\to\ &\text{\textbf{(def of fix)}}\\
&3 * \big(F(\mathrm{fix}\ F)\big)\,2\\
\to\ &\text{\textbf{($\beta$)}}\\
&3 * (\lambda n.\ \mathrm{if}\ n=0\ \mathrm{then}\ 1\ \mathrm{else}\ n * (\mathrm{fix}\ F)(n-1))\ 2\\
\to\ &\text{\textbf{($\beta$; substitute $2$ for $n$)}}\\
&3 * \big(\mathrm{if}\ 2=0\ \mathrm{then}\ 1\ \mathrm{else}\ 2 * (\mathrm{fix}\ F)(1)\big)\\
\to\ &\text{\textbf{(def of if)}}\\
&3 * \big(2 * (\mathrm{fix}\ F)(1)\big)\\
\to\ &\text{\textbf{(def of fix)}}\\
&3 * \big(2 * \big(F(\mathrm{fix}\ F)\big)\,1\big)\\
\to\ &\text{\textbf{($\beta$)}}\\
&3 * \big(2 * (\lambda n.\ \mathrm{if}\ n=0\ \mathrm{then}\ 1\ \mathrm{else}\ n * (\mathrm{fix}\ F)(n-1))\ 1\big)\\
\to\ &\text{\textbf{($\beta$; substitute $1$ for $n$)}}\\
&3 * \big(2 * \big(\mathrm{if}\ 1=0\ \mathrm{then}\ 1\ \mathrm{else}\ 1 * (\mathrm{fix}\ F)(0)\big)\big)\\
\to\ &\text{\textbf{(def of if)}}\\
&3 * \big(2 * \big(1 * (\mathrm{fix}\ F)(0)\big)\big)\\
\to\ &\text{\textbf{(def of fix)}}\\
&3 * \big(2 * \big(1 * \big(F(\mathrm{fix}\ F)\big)\,0\big)\big)\\
\to\ &\text{\textbf{($\beta$)}}\\
&3 * \big(2 * \big(1 * (\lambda n.\ \mathrm{if}\ n=0\ \mathrm{then}\ 1\ \mathrm{else}\ n * (\mathrm{fix}\ F)(n-1))\ 0\big)\big)\\
\to\ &\text{\textbf{($\beta$; substitute $0$ for $n$)}}\\
&3 * \big(2 * \big(1 * (\mathrm{if}\ 0=0\ \mathrm{then}\ 1\ \mathrm{else}\ 0 * (\mathrm{fix}\ F)(-1))\big)\big)\\
\to\ &\text{\textbf{(def of if)}}\\
&3 * \big(2 * (1 * 1)\big) \;=\; 3 * 2 * 1 \;=\; \boxed{6}.
\end{aligned}
\]

\subsubsection*{Problem B: Y-combinator factorial and one unfold}
Let
\[
Y \equiv \lambda g.\ (\lambda x.\ g(x\,x))(\lambda x.\ g(x\,x)),\quad
G \equiv \lambda f.\ \lambda n.\ \mathrm{if}\ n=0\ \mathrm{then}\ 1\ \mathrm{else}\ n * f(n-1).
\]
Define $\mathrm{fact} \equiv YG$. Then
\[
\mathrm{fact} \;=\; YG \;\to\; G(YG) \;=\; \lambda n.\ \mathrm{if}\ n=0\ \mathrm{then}\ 1\ \mathrm{else}\ n * (YG)(n-1),
\]
which is exactly one recursive ``unfold''.

\begin{remark}
In total/strongly normalizing typed calculi, $Y$ cannot be defined without sacrificing termination. Practical languages provide explicit recursion or \texttt{fix}, often with typing restrictions.
\end{remark}

% ============================
\section{Week 7: Grammars, Parse Trees, and ASTs}
% ============================

\subsection{Class Notes \& Discussion}

\begin{itemize}
  \item \textbf{Fixed-point combinators and performance.} Using $Y$/\texttt{fix} introduces an extra unfolding step ($YF \to F(YF)$). Named recursion or \texttt{let rec} generally performs better since the compiler can optimize it directly without creating closures on each call.
  \item \textbf{LLMs as metaprograms.} Large language models can be viewed as metaprograms that translate semantics (intent or meaning) into code. However, they do not replace the traditional compiler pipeline—semantic interpretation, parsing, optimization, and execution still occur afterward.
  \item \textbf{Lisp and syntax readability.} Lisp’s simple S-expression syntax gives programmers direct access to abstract syntax, making metaprogramming and macro systems easier to implement. The trade-off is reduced human readability but increased ease of parsing for machines.
  \item \textbf{Ambiguous grammars.} Ambiguity in grammars can make parsing inconsistent; precedence and associativity rules often disambiguate.
  \item \textbf{Parse trees vs.\ ASTs.} Parse trees include every token; ASTs compress away redundant structure (e.g., parentheses) to expose semantics for analysis and code generation.
\end{itemize}

\subsection{Homework 7: Context-Free Grammar and Derivation Trees}

Grammar:
\[
\begin{array}{rcl}
\text{Exp} &\to& \text{Exp}\;+\;\text{Exp1}\ \mid\ \text{Exp1}\\
\text{Exp1} &\to& \text{Exp1}\;*\;\text{Exp2}\ \mid\ \text{Exp2}\\
\text{Exp2} &\to& \text{Integer}\ \mid\ (\,\text{Exp}\,)
\end{array}
\]

\paragraph{(a) \texttt{2+1}}
\begin{center}
\begin{tikzpicture}[grow=down,level distance=10mm, every node/.style={font=\small}]
\node{Exp}
 child{ node{Exp}
   child{ node{Exp1}
     child{ node{Exp2}
       child{ node{Integer} child{ node{$2$} } }}}}
 child{ node{$+$} }
 child{ node{Exp1}
   child{ node{Exp2}
     child{ node{Integer} child{ node{$1$} } }}};
\end{tikzpicture}
\end{center}

\paragraph{(b) \texttt{1+2*3}}
\begin{center}
\begin{tikzpicture}[grow=down,level distance=10mm, every node/.style={font=\small}]
\node{Exp}
 child{ node{Exp}
   child{ node{Exp1}
     child{ node{Exp2}
       child{ node{Integer} child{ node{$1$} } }}}}
 child{ node{$+$} }
 child{ node{Exp1}
   child{ node{Exp1}
     child{ node{Exp2}
       child{ node{Integer} child{ node{$2$} } }}}
   child{ node{$*$} }
   child{ node{Exp2}
     child{ node{Integer} child{ node{$3$} } }}};
\end{tikzpicture}
\end{center}

\paragraph{(c) \texttt{1+(2*3)}}
\begin{center}
\begin{tikzpicture}[grow=down,level distance=10mm, every node/.style={font=\small}]
\node{Exp}
 child{ node{Exp}
   child{ node{Exp1}
     child{ node{Exp2}
       child{ node{Integer} child{ node{$1$} } }}}}
 child{ node{$+$} }
 child{ node{Exp1}
   child{ node{Exp2}
     child{ node{$($} }
     child{ node{Exp}
       child{ node{Exp1}
         child{ node{Exp1}
           child{ node{Exp2}
             child{ node{Integer} child{ node{$2$} } }}}
         child{ node{$*$} }
         child{ node{Exp2}
           child{ node{Integer} child{ node{$3$} } }}}}
     child{ node{$)$} }}};
\end{tikzpicture}
\end{center}

\paragraph{(d) \texttt{(1+2)*3}}
\begin{center}
\begin{tikzpicture}[grow=down,level distance=10mm, every node/.style={font=\small}]
\node{Exp}
 child{ node{Exp1}
   child{ node{Exp1}
     child{ node{Exp2}
       child{ node{$($} }
       child{ node{Exp}
         child{ node{Exp}
           child{ node{Exp1}
             child{ node{Exp2}
               child{ node{Integer} child{ node{$1$} } }}}}
         child{ node{$+$} }
         child{ node{Exp1}
           child{ node{Exp2}
             child{ node{Integer} child{ node{$2$} } }}}}
       child{ node{$)$} }}}
   child{ node{$*$} }
   child{ node{Exp2}
     child{ node{Integer} child{ node{$3$} } }}};
\end{tikzpicture}
\end{center}

\paragraph{(e) \texttt{1+2*3+4*5+6}}
\begin{center}
\begin{tikzpicture}[grow=down,level distance=10mm, sibling distance=18mm, every node/.style={font=\small}]
\node{Exp}
  child{ node{Exp}
    child{ node{Exp}
      child{ node{Exp}
        child{ node{Exp1}
          child{ node{Exp2}
            child{ node{Integer} child{ node{$1$} } }}}}
      child{ node{$+$} }
      child{ node{Exp1}
        child{ node{Exp1}
          child{ node{Exp2}
            child{ node{Integer} child{ node{$2$} } }}}
        child{ node{$*$} }
        child{ node{Exp2}
          child{ node{Integer} child{ node{$3$} } }}}}
    child{ node{$+$} }
    child{ node{Exp1}
      child{ node{Exp1}
        child{ node{Exp2}
          child{ node{Integer} child{ node{$4$} } }}
        }
      child{ node{$*$} }
      child{ node{Exp2}
        child{ node{Integer} child{ node{$5$} } }}}}
  child{ node{$+$} }
  child{ node{Exp1}
    child{ node{Exp2}
      child{ node{Integer} child{ node{$6$} } }}};
\end{tikzpicture}
\end{center}

% ============================
\section{Week 8: Natural Number Game (Tutorial World)}
% ============================

\subsection{Notes \& Setup}
This task connects informal English proofs with formal Lean steps. In the Tutorial World we use facts like
\[
a+0=a,\qquad a+\mathrm{succ}(b)=\mathrm{succ}(a+b),\qquad 1=\mathrm{succ}(0),
\]
and finish goals by reflexivity (\texttt{rfl}) after rewriting.

\subsection{Selected Level Solutions (5--8)}
Below are minimal tactic scripts matching the in-game steps. (They are illustrative—other equivalent scripts also pass.)

\paragraph{Level 5 — Adding zero (right).}
\begin{lstlisting}[language=Haskell]
rw [add_zero b]
rw [add_zero c]
rfl
\end{lstlisting}

\paragraph{Level 6 — Careful rewriting.}
\begin{lstlisting}[language=Haskell]
rw [add_zero b]
rw [add_zero c]
rfl
\end{lstlisting}

\paragraph{Level 7 — Show  a + 1 = succ a.}
\begin{lstlisting}[language=Haskell]
rw [one_eq_succ_zero]
rw [add_succ]
rw [add_zero]
rfl
\end{lstlisting}

\paragraph{Level 8 — Compute 2 + 2 = 4.}
\begin{lstlisting}[language=Haskell]
-- Use 2 = succ 1 and 1 = succ 0, then unfold addition by add_succ
nth_rewrite 2 [two_eq_succ_one]
rw [add_succ 2]
nth_rewrite 1 [one_eq_succ_zero]
-- continue rewrites until the goal closes by rfl
\end{lstlisting}

\subsection{Class Notes \& Discussion}
\begin{itemize}
  \item \textbf{English vs.\ Lean proofs.} The Lean script mirrors an English proof by repeatedly replacing equals by equals (rewrite) until both sides are syntactically identical (\texttt{rfl}).
  \item \textbf{Core facts used.} Right identity of addition ($a+0=a$), right recursion ($a+\mathrm{succ}(b)=\mathrm{succ}(a+b)$), and numeral definitions ($1=\mathrm{succ}(0)$, $2=\mathrm{succ}(1)$).
  \item \textbf{Tactics as rules of inference.} Each \texttt{rw} corresponds to applying an equality as a substitution rule; the order of rewrites matters to expose the shape needed for the next lemma.
  \item \textbf{Why recursion on the right?} Defining $+$ by recursion on the second argument gives the simple law above and simplifies induction proofs on the right operand. Recursing on the left would require different lemmas (e.g., $\mathrm{succ}(a)+b=\mathrm{succ}(a+b)$) and different induction patterns.
  \item \textbf{Equality reasoning pattern.} Normalize numerals $\to$ unfold by recursive law \texttt{add\_succ} repeatedly $\to$ discharge with identities like \texttt{add\_zero} $\to$ finish with \texttt{rfl}.
\end{itemize}
% ============================
\section{Week 9: Addition World — Two Proofs \& Notes}
% ============================

\subsection{Notes \& Discussion (Q\&A)}

\paragraph{Boundary between definitional and propositional equality.}
\emph{Definitional} (or judgmental) equality is what the kernel reduces by computation/expansion and treats as the \emph{same term} (e.g.\ $\mathrm{Nat.add}\ a\ 0 \equiv a$, $\beta$-, $\delta$-, $\iota$-reductions). No proof object is needed; goals discharge by \texttt{rfl} or \texttt{simp} that performs computation.  
\emph{Propositional} equality (\texttt{Eq}) is a type inhabited by a proof term (e.g.\ a chain of rewrites) showing two \emph{a priori} different terms are equal; it is manipulated with lemmas like \texttt{add\_assoc}, \texttt{congrArg}, \texttt{calc}, etc. Intuition: definitional = computation; propositional = reasoning about equality beyond raw computation.

\paragraph{How $\mathbb{N}$’s inductive definition enables recursive $+$.}
With \texttt{inductive Nat | zero | succ : Nat → Nat}, primitive recursion defines $a + n$ by
\[
a + 0 \;=\; a,\qquad a + \mathrm{succ}(n) \;=\; \mathrm{succ}(a+n).
\]
Because \texttt{Nat.rec} (or \texttt{Nat.recOn}) eliminates on the second argument, the recursion equations above are \emph{defining} equalities that Lean can compute with directly.

\paragraph{SOLID in Lean / math-centric code.}
\begin{itemize}
  \item \textbf{S}ingle Responsibility: lemmas should prove exactly one fact; larger theorems compose small lemmas.
  \item \textbf{O}pen/Closed: extend the library with new lemmas (open), don’t rewrite core definitions (closed).
  \item \textbf{L}iskov Substitution: use typeclasses/instances (\texttt{Semiring}, \texttt{Monoid}) so theorems work for any instance.
  \item \textbf{I}nterface Segregation: expose minimal lemma interfaces; avoid giant \texttt{simp} sets that do too much.
  \item \textbf{D}ependency Inversion: reason at the level of algebraic interfaces rather than concrete \texttt{Nat} when possible.
\end{itemize}
Math-first programming prizes \emph{specification and proof}; SOLID maps well to clean lemma factoring and reusable abstractions.

\paragraph{Do all computational equality proofs end with \texttt{rfl}?}
No. Goals that are definitionally equal can close by \texttt{rfl}. Many “computational” goals can also finish via \texttt{simp} (using definitional rules like \texttt{Nat.add\_zero}, \texttt{Nat.add\_succ}). When non-computational rearrangements are needed (associativity/commutativity), we end with a lemma-driven chain or \texttt{simp}+\texttt{ring}-style tactics, not necessarily \texttt{rfl}.

\paragraph{Double induction for \texttt{add\_right\_comm} without \texttt{add\_comm}/\texttt{add\_assoc}?}
Yes in principle: prove $P(b,c): a+b+c=a+c+b$ for all $a$ by outer induction on $c$ and inner induction on $b$, using only the defining equations of $+$ and \texttt{succ} injectivity. It is longer and more technical in Lean because you must re-establish associativity-like rearrangements manually. Using standard lemmas is far shorter and idiomatic.

\paragraph{How logic/maths proofs deepen Lean and industry skills.}
They enforce precise specs, decomposition into lemmas (modularity), and automated checking (CI-like guarantees). This is directly transferable to testing, refactoring, and API design.

\paragraph{Induction vs.\ algebraic lemmas (comm/assoc).}
Being able to reach the same theorem both ways shows \emph{strategy choice}: induction exposes structure and well-founded decrease; lemma-based algebra leverages previously proved facts. In algorithm design this mirrors \emph{design space exploration}: choose recursion/iteration (structural approach) or algebraic transformations/identities (law-driven approach) depending on clarity and cost.

\medskip

\noindent\textit{Reference you cited (Tutorial World L8):} \url{https://adam.math.hhu.de/#/g/leanprover-community/nng4/world/Tutorial/level/8}

% -------------------------------------------------
\subsection{Homework 9: Addition World — Level 5 (two solutions)}
% -------------------------------------------------

\paragraph{Statement (as in Addition World, right-commuting the tail).}
We show, for all $a,b,c\in\mathbb{N}$,
\[
a + b + c \;=\; a + c + b\qquad\text{(often called \texttt{add\_right\_comm}).}
\]

\subsubsection*{Solution 1 (non-inductive, via lemmas).}
\begin{lstlisting}
-- Lean 4
theorem add_right_comm' (a b c : Nat) :
  a + b + c = a + c + b := by
  -- reshape: (a + b) + c  ≡  a + (b + c)
  calc
    a + b + c = a + (b + c) := by simp [Nat.add_assoc]
    _          = a + (c + b) := by simpa [Nat.add_comm]
    _          = a + c + b   := by simp [Nat.add_assoc]
\end{lstlisting}

\noindent\textbf{Pen-and-paper proof.}
Using associativity and commutativity of $+$,
\[
(a+b)+c \;=\; a+(b+c) \;=\; a+(c+b) \;=\; (a+c)+b.
\]
Each step is a standard ring law; hence $a+b+c = a+c+b$.

\subsubsection*{Solution 2 (inductive).}
We prove $P(c):\ \forall a b.\ a+b+c=a+c+b$ by induction on $c$.

\begin{lstlisting}
-- Lean 4
theorem add_right_comm_ind (a b c : Nat) :
  a + b + c = a + c + b := by
  induction c with
  | zero =>
      -- a + b + 0 = a + 0 + b
      simp [Nat.add_assoc, Nat.add_zero, Nat.zero_add]
  | succ c ih =>
      -- goal: a + b + succ c = a + succ c + b
      -- use the recursion equation for addition on the right argument
      -- x + succ c = succ (x + c)
      simp [Nat.add_assoc, ih]
\end{lstlisting}

\noindent\textbf{Pen-and-paper proof (matching the code).}
Define $P(c)\!:\!\forall a,b,\ (a+b)+c=(a+c)+b$.  
\emph{Base $c=0$:} $(a+b)+0=a+b=a+0+b$ by $x+0=x$ and $0+x=x$.  
\emph{Step $c\mapsto c+1$:}
\[
\begin{aligned}
(a+b)+(c+1) &= \mathrm{succ}\big((a+b)+c\big) &&\text{(def.\ of $+$)}\\
            &= \mathrm{succ}\big((a+c)+b\big) &&\text{(IH)}\\
            &= (a+(c+1))+b                      &&\text{(def.\ of $+$)}\\
            &= a+(c+1)+b.
\end{aligned}
\]
Thus $P(c)$ holds for all $c$, so $a+b+c=a+c+b$.

\paragraph{Remark on lengths.}
The non-inductive proof is a three-line \texttt{calc}. The double-inductive route (or the single induction above) is longer because it reconstructs rearrangements using only the defining equations and the inductive hypothesis.

\subsubsection*{(Optional) What Level 5 asked and how this satisfies it.}
The assignment asked for \emph{two distinct solutions}: one relying on computation/lemmas and another by induction, each with a corresponding “pen-and-paper” argument. The two proofs above meet those requirements.


\begin{thebibliography}{99}
\bibitem[BLA]{bla} Author, \href{https://en.wikipedia.org/wiki/LaTeX}{LaTeX Overview}, Publisher, Year.
\end{thebibliography}

\end{document}
